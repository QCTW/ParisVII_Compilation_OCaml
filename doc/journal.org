#+STARTUP: hidestars
#+TODO: TODO(t!) STARTED(s@/!) WAITING(w@/!) SOMEDAY(S@/!) | DONE(d!) CANCELED(c@!)
#+PRIORITIES: A C B

			   *Cours de Compilation*

(Il est préférable d'ouvrir ce fichier texte sous Emacs.)
(Appuyez sur [TAB] pour dérouler les items suivis de "...")

* Cours 1 <2016-09-12>
** Introduction du cours
*** Qu'est-ce qu'un compilateur?
    - définition informelle
    - syntaxe et sémantique d'un langage de programmation
    - définition formelle
*** Pourquoi un cours de compilation en M1?
    - devenir de meilleurs programmeurs
    - apprendre des techniques de programmation utiles au développement
    - un sujet transversal de l'informatique
** Préliminaire: un sondage
   - Qui a déjà programmé en OCaml?
   - Qui a déjà écrit un analyseur syntaxique?
   - Qui a suivi le cours de machine virtuelle?
** Un mini-compilateur pour le langage Marthe
   - voir le fichier marthe.ml
** Le projet de compilation
   - description du projet
   - architecture du projet
   - travail demandé
   - présentation de l'arbre des sources
** Fonctionnement du cours
   - un cours dans Emacs et au tableau
   - un cours orienté "projet"
   - deux semestres pour un premier "gros" projet
   - les jalons et leurs validations
   - des soutenances
   - modalités d'évaluation:
     70% projet + 30% examen sur papier (portant sur le projet)
     Sur la note de projet, 3 points réservés:
     - 1 point si vous avez posé (ou répondu à) au moins 5 questions
       (productions pertinentes, bien formulées) sur le forum.
     - 1 point si vous avez contribué à la réussite globale du projet
       en faisant au moins 5 "pull requests" sur le projet GIT public.
     - 1 point si la moyenne de la promo (moins les "fantômes") est supérieur à 13.
*** DONE Forker le GIT via le gitlab:
    - State "DONE"       from "TODO"       [2016-10-23 Sun 13:14]
    http://moule.informatique.univ-paris-diderot.fr:8080
    DEADLINE:<2016-09-19>
*** DONE Remplir le fichier AUTEURS (2 étudiants par groupes)
    DEADLINE:<2016-09-19>
    - State "DONE"       from "TODO"       [2016-10-23 Sun 13:14]
*** DONE Rajouter les enseignants (via gitlab)
    DEADLINE:<2016-09-19>
    - State "DONE"       from "TODO"       [2016-10-23 Sun 13:15]
    Pierre Letouzey
    Michele Pagani
    Yann Regis-Gianas
*** DONE Faire une pull-request pour mettre à jour le fichier /.mrconfig
    DEADLINE:<2016-09-19>
    - State "DONE"       from "TODO"       [2016-10-23 Sun 13:15]
*** TODO S'inscrire sur http://faq.compilation.hackojo.org
    DEADLINE:<2016-09-19>
*** DONE S'inscrire sur https://groups.google.com/forum/#!forum/compilix
    DEADLINE: <2016-09-19>
    - State "DONE"       from "TODO"       [2016-10-23 Sun 13:16]
*** TODO Travailler régulièrement sur le GIT.
*** TODO Poser des questions sur le site FAQ
* Cours 2 <2016-09-19>
** Retour sur le fonctionnement du cours
   - Forker le GIT.
   - Lire les TODOs dans doc/journal.org
   - 2 cours puis 1 TP
   - Prendre des notes
** L'arbre de sources du compilateur Flap
   - Makefile
   - Arborescence
   - Modules généraux: Languages, Compilers, Flap
   - MiniHopix
   - Méthode de développement dirigée par les tests et incrémentale.
** Les générateurs de code
   - Qu'est-ce que c'est?
   - Pourquoi les utiliser?
** Analyse lexicale
   - Définition
   - Lexèmes et valeurs sémantiques
   - ocamllex
** DONE Lire la documentation de OCamllex
   - State "DONE"       from "TODO"       [2016-11-01 Tue 15:45]
** DONE Lire la documentation de Menhir
   - State "DONE"       from "TODO"       [2016-11-01 Tue 15:45]
** DONE TD1
   - State "DONE"       from "TODO"       [2016-11-01 Tue 15:46]
* Cours 3 <2016-10-03>
** Analyse syntaxique: les définitions
   - Langages
   - Grammaire algébrique
   - Hiérarchie de Chomsky
   - Dérivation d'un mot par une grammaire
   - Multiples dérivations, dérivations équivalentes pour l'analyse
   - Arbre de dérivation d'un mot
   - Ambiguïté
   - Formalisation du problème de l'analyse syntaxique
   - Arbre de syntaxe concrète et arbre de syntaxe abstraite
** Classification des algorithmes d'analyses syntaxiques
   - Algorithmes ascendants
   - Algorithmes descendants
** Menhir, point de vue utilisateur
** Références bibliographiques
   - Appel, "Modern Compiler Implementation" (à la bibliothèque)
   - Grune, "Parsing techniques" (PDF en ligne)
* Cours 4 <2016-10-17>
** Unger
** LL(1)
* Cours 5 <2016-11-07>
** Point projet
** Earley
** LR(0)
** LR(1)
** LALR(1)
* Cours 6 <2016-11-14>
** Point projet
** Syntaxe!
*** BNF d'arbres
    e ::= n | e + e | e * e

    type e = Int of int | Plus of e * e | Mul of e * e
*** Sémantique à petits pas

    ——————————
     1 + 2 → 3
    ———————————————————
    (1 + 2) + 3 → 3 + 3

    —————————
    3 + 3 → 6

*** Différence entre "let x = 1 in ..." et "int x = 1; ..."

    int x = 1;
    y = x + 1;
    ...

    let x = f y in
    x + x

*** Occurrences libres et liées

    let y = *x* in
    let x = 0 in
      /x/ + y

    (en gras : une occurrence libre de x.)
    (en italique : une occurrence liée de x.)

    On peut renommer une occurrence liée :

    let y = *u* in
    let z = 0 in
      /z/ + y


    let x = *x* in /x/

*** Explicitation des fermetures

    y ∈ FV (fun x -> x + y)

    (fun x -> x + y)[ y = 10 ]

* Cours 7 <2016-12-05>
** Rappel des épisodes précédents
   - Notion de syntaxe
   - Notion de liaison de noms
   - Les pointeurs de fonction en C ne sont pas des représentations
     sérieuses des fonctions
   - La notion de fermeture

** Différents évaluateurs pour un langage arithmétique avec "let"
   - Sémantique à petits pas
   - Sémantique à grands pas avec environnements d'évaluation
** Jalon 2 du projet
   - Présentation de la spécification de l'année dernière
   - Règles du "while"
* Cours 8 <2016-12-12>
** Analyse statique
   - Bonne liaison des noms
** Compilation vers une machine
* Cours 9 <2016-12-14> de 9h30 à 11h30 en salle 1008
** Jalon 2
** Examen
** Les fonctions de seconde classe
** Les fonctions de première classe
* Cours 10 <2017-01-17>
** Exceptionnellement, séance de 1h15
** Pas de TD cette semaine
** Où est parti le forum?
** Retour sur le jalon 2
** Présentation de la chaîne de compilation
*** Hopix    -> Hobix
*** Hobix    -> Fopix
*** Fopix    -> Retrolix
*** Retrolix -> Retrolix
*** Retrolix -> MIPS
** TODO Lire la spécification de MIPS
* Cours 11 <2017-01-24>
** TODO MIPS
** TODO Le typage
* Cours 12 <2017-01-31>
** TODO Typage
* Cours 13 <2017-02-07>
** Retour sur le typage
** Inférence de type
*** Problème
    Un programme pas ou peu annoté comme par exemple:

          let f = fun x -> x + 1

*** Solutions
**** Algorithme W
        Soit α le type de x.

	En supposant (x : α), essayons de calculer le
	type de "( + ) x 1". C'est une application, je
	calcule le type de la fonction. `+ a le type
	"int -> (int -> int)". Je dois dois vérifier
	que "x" a le type de l'entrée de cette fonction.

	On doit alors *unifier* le type connu pour "x" et
	le type attendu pour "x". Cela veut que l'on unifie
	"α" et "int".

	On doit aussi vérifier que 1 a le type int.

	Puis on peut déduire que le type de l'application
	est le type de retour de +, i.e. int.

	Donc le type de l'expression "fun x -> x + 1" est
	donc "int -> int".

***** Unification du premier ordre

******* Exemple 1

	P₀ := α₁ -> α₁ =? (α₂ -> int) -> (int -> α₃)

	Au départ la file des problèmes contient seulement
	P₀. On observe le premier problème de la file, c'est P.
	Comme les deux termes à unifier ne sont pas des variables,
	on doit les décomposer : cela insère deux nouveaux problèmes:

	P₁ := α₁ =? (α₂ -> int)
	P₂ := α₁ =? (int -> α₃)

	Par P₁, j'apprends que φ(α₁) = α₂ -> int

	Par P₂, j'apprends que φ(α₁) = int -> α₃

	Comme j'avais déjà une information sur α₁ dans
	φ, je produis un nouveau problème pour vérifier
	que φ reste cohérent:

	P₃ := α₂ -> int =? int -> α₃

	J'applique la règle de décomposition:

	P₄ := α₂ =? int
	P₅ := int =? α₃

	Par P₄, j'apprends que φ(α₂) = int
	Par P₅, j'apprends que φ(α₃) = int

	donc ma solution du problème d'unification initial est:

	φ(α₁) = int -> int
	φ(α₂) = int
	φ(α₃) = int

******* Exemple 2

	P₀ := α₁ -> α₁ =? (α₂ -> α₃) -> (int -> α₃)

	Ici, α₃ n'est pas déterminé.

      L'algorithme W s'appuie sur l'unification du premier ordre.

      t =^? u  –> ⊥ | substitution φ

      On travaille sur une file de problèmes à résoudre,
      chaque problème est un problème d'unification et
      on construit une substitution φ au fur et à mesure
      de la résolution de ces problèmes. On doit
      vérifier que φ n'a pas de cycle.

      • Règle des variables:
      x =? u

      • Règle de décomposition:
      f(t₁, …, tₙ) = f (u₁, …, uₙ) →
      alors on rajoute les nouveaux problèmes
      tᵢ = uᵢ

      f(t₁, …, tₙ) = g(u₁, …, uₘ) → ⊥

***** Généralisation

      let id = fun x -> x in (id 0, id true)

      (x : α) |- x : α
      —————————————————————————–
      |- fun x -> x : α -> α
      —————————————————————————–
      |- fun x -> x : ∀α. α -> α     (id : ∀α. α -> α) ⊢ (id 0, id true) : int × bool
      ————————————————————————————————————————————————————–————————————–————————————–
                |- let id = fun x -> x in (id 0, id true) : int × bool

**** La génération de contraintes

     [ let apply = fun f x -> f x ] =

     def apply : ∀α[∃γβγ₁γ₂. α = γ₁ -> γ₂ ∧ γ₁ = (γ -> β) ∧ γ₂ = γ -> β].α

** Jalon 3
** Datix
** Hopix -> Datix
*** Compilation du pattern-matching
**** avec des "ifs"

     En Hopix:

       fun len (l) = f (l) ? Nil => 0 | Cons (x, xs) => 1 + len (xs)

     est compilé en Datix comme suit:

       fun len (l) =
         val _l_ = f (l);
	 if _l_[0] = 0 then
	   0
	 else if _l_[0] = 1 then
	   val x = _l_[1];
	   val xs = _l_[2];
	   1 + len (xs)




      Un autre exemple:

        fun uniq (l) = l ? {
	| Nil => true
	| Cons (x, Nil) => true
        | Cons (x, Cons (y, xs)) => x <> y && uniq (Cons (y, xs))
        }

      est compilé:

        fun uniq (l) =
          if l[0] = 0 then
            true
          else if l[0] = 1 && l[2][0] = 0 then
            true
          else if l[0] = 1 && l[2][0] = 1 then
            val x = l[1];
            val y = l[2][1];
	    val xs = l[2][2];
            x <> y && uniq (val b = block 2; b[0] = 1; b[1] = y; b[2] = xs)

        fun uniq (l) =
          switch l[0] {
	  case 0:
	     true
	  case 1:
	     switch l[2][0] {
	       case 0: 
	          true
	       case 1:
                  val x = l[1];
                  val y = l[2][1];
    	          val xs = l[2][2];
                  x <> y && uniq (val b = block 2; b[0] = 1; b[1] = y; b[2] = xs)
	     }
          }
 
        fun foo (l) = l ? {
        | (A(x) | B(x)) => x
        }

* Cours 14 <2017-02-14>
** Hopix -> Datix
*** Compilation du pattern-matching
**** Des choix dans le pattern-matching
#+BEGIN_EXAMPLE
\x => x ? {
  Pair (A, A) => 0
| Pair (A, B) => 1
| Pair (_, C) => 2
| Pair (_, _) => 3
}
#+END_EXAMPLE

**** Développement des motifs disjonctifs
#+BEGIN_EXAMPLE
\x => x ? {
| Pair ((A | B | C), (A | B)) => 0
| Pair ((A | B), (B | C)) => 1
}
** Implémentation de DATIX
*** Syntaxe concrète
*** Interpréteur
* Cours 15 <2017-02-21>
** DONE Retour sur Jalon 3
** DONE Préparation du TD sur Datix
** TODO Présentation de Fopix
   - Un langage proche de C, un langage du premier ordre.
** TODO Présentation de Retrolix
   - val x = 1 + 2 * 3;
     val y = x + x;
     y

     se compile en:

     z <- * [2, 3]
     x <- + [1, z]
     y <- + [x, x]
     ret y

   - while b { e }

     se compile:

     l:
	"instructions of b -> B"
	jmpif B -> l1, l2
     l1:
	"instructions of e"
        jmp l
     l2:
	"the rest of the instructions"


    - if c then e1 else e2

      se compile en:

      "instructions of c -> B"
      jmpif B -> l1, l2

      l1:
          "instructions of e1"
	  jmp l3
      l2:
          "instructions of e2"
          jmp l3
      l3:
          ...

* Cours 15 <2017-02-28>
** Allocation de registres, késako?

   ReTroLix : RTL-like languages
   Register Transfer Language

   r3 <- r1 + r2

   Problème: dans Retrolix, nous avons considéré qu'il y a un
   ensemble infini de registres. On les appelle d'ailleurs des
   *pseudo-registres*.

** Un exemple

   l1: r1 <- 100     -> l2
   l2: r2 <- 0       -> l3
   l3: r3 <- 3       -> l4
   l4: cmp r1 = 0    -> l8, l5
   l5: r2 <- r2 + r3 -> l6
   l6: r1 <- r1 - 1  -> l7
   l7: jmp l4        -> l3
   l8: exit

   Supposons que la machine n'a que deux registres a et b.

   l1: a <- 100      -> l2
   l2: b <- 0        -> l3
   l3: r3 <- 3       -> l4
   l4: cmp a = 0     -> l8, l5
   l5: b <- b + r3   -> l6
   l6: a <- a - 1    -> l7
   l7: jmp l4        -> l3
   l8: exit

   Après la propagation des constantes, on obtient:

   l1: a <- 100      -> l2
   l2: b <- 0        -> l4
   l4: cmp a = 0     -> l8, l5
   l5: b <- b + 3    -> l6
   l6: a <- a - 1    -> l7
   l7: jmp l4        -> l3
   l8: exit

** Interférence entre variables

   La règle pour qu'une certaine allocation de registres soit valide,
   c'est que deux pseudoregistres (les rk) qui sont utiles en même
   temps, on dit en fait qui sont "vivants en même temps" ne sont pas
   représentés par le même registre physique.

** Décomposition de l'allocation de registres 

   On doit répondre à deux questions:

   1. Quelles sont les variables/pseudoregistres qui sont vivantes en même temps?
      => La réponse à cette question est un graphe d'interférence.
      Ses noeuds ce sont les pseudoregistres et il y aura une arête entre deux noeuds
      si les pseudoregistres de ces noeuds vivent en même temps.

   2. Sachant les interférences entre variables, comment allouer du mieux possible
      des registres physiques aux variables?
      Cela revient à *colorier* le graphe.

   Une fois que l'on a trouvé un coloriage, peut réécrire le programme Retrolix
   en remplaçant chaque pseudoregistre par son registre physique correspond ou
   pas, s'il n'a pas été colorié.

** Retour sur l'exemple:

   Dans notre exemple, r1, r2 et r3 sont toutes vivantes en même
   temps: le graphe d'interférence est donc complet et on ne peut pas
   le colorier avec seulement deux couleurs.

   Voici un nouvel exemple:

   l1: r1 <- 100     -> l2
   l2: r2 <- 0       -> l3
   l3: r3 <- 3       -> l4
   l4: cmp r1 = 0    -> l8, l5
   l5: r2 <- r2 + r3 -> l6
   l6: r1 <- r1 - 1  -> l7
   l7: jmp l4        -> l3
   l8: r4 <- r2 * r1 -> l9
   l9: r5 <- r3 + 1  -> l10
   l10: ret (r5 + r4)

   se réécrit en :

   l1: a <- 100      -> l2
   l2: b <- 0        -> l3
   l3: r3 <- 3       -> l4
   l4: cmp a = 0     -> l8, l5
   l5: b <- b + r3   -> l6
   l6: a <- a - 1    -> l7
   l7: jmp l4        -> l3
   l8: b <- b * a    -> l9
   l9: a <- r3 + 1   -> l10
   l10: ret (a + b)

   Voici encore un nouvel exemple:

   l1: r1 <- 100     -> l2
   l2: r2 <- 0       -> l3
   l3: r3 <- 3       -> l4
   l4: cmp r1 = 0    -> l8, l5
   l5: r2 <- r2 + r3 -> l6
   l6: r1 <- r1 - 1  -> l7
   l7: jmp l4        -> l3
   l8: r4 <- r2 * r1 -> l9
   l9: r5 <- r3 + 1  -> l10
   l10: ret r5

   Ici, r4 n'est pas une variable utile donc le programme peut finalement
   s'optimiser drastiquement!

   l10: ret 4

** Analyse de vivacité

   L'analyse de vivacité, c'est une analyse statique.

   IN(l1)  associe l'ensemble des variables vivantes à l'entrée de l1.
   OUT(l1) associe l'ensemble des variables vivantes à la sortie de l1.

   x ∈ IN(l)  si x ∈ (OUT(l) \ DEF(l)) ∨ (∃ l' -> l, x ∈ OUT(l')) ∨ x ∈ USE(l)
   x ∈ OUT(l) si ∃ l', l -> l', x ∈ IN(l')

   l1: r1 <- 100     -> l2
   l2: r2 <- 0       -> l3
   l3: r3 <- 3       -> l4
   l4: cmp r1 = 0    -> l8, l5
   l5: r2 <- r2 + r3 -> l6
   l6: r1 <- r1 - 1  -> l7
   l7: jmp l4        -> l4
   l8: r4 <- r2 * r1 -> l9
   l9: r5 <- r3 + 1  -> l10
   l10: ret (r5 + r4)

**** Calcul en avant

   En itérant sur le programme plusieurs fois du début à la fin, on
   arrive péniblement à faire avancer les approximations des variables
   vivantes... mais c'est terriblement long! C'est tellement que je ne
   suis allé jusqu'au bout et que je me suis endormi.

   |-----+----------+---------|
   | L   | IN       | OUT     |
   |-----+----------+---------|
   | l1  | {}       | {}      |
   | l2  | {}       | {}      |
   | l3  | {}       | {r1}    |
   | l4  | {r1}     | {r2,r3} |
   | l5  | {r2, r3} | {r1}    |
   | l6  | {r1}     | {}      |
   | l7  | {r1}     | {r1}    |
   | l8  | {r2, r1} | {}      |
   | l9  | {r3}     | {}      |
   | l10 | {r4, r5} | {}      |
   |-----+----------+---------|

**** Calcul en arrière

   |-----+--------------+--------------|
   | L   | IN           | OUT          |
   |-----+--------------+--------------|
   | l1  | {}           | {r1}         |
   | l2  | {r1}         | {r1, r2}     |
   | l3  | {r1, r2}     | {r1, r2, r3} |
   | l4  | {r1, r2, r3} | {r1, r2, r3} |
   | l5  | {r1, r2, r3} | {r1, r2, r3} |
   | l6  | {r1, r2, r3} | {r1, r2, r3} |
   | l7  | {r1, r2, r3} | {r1, r2, r3} |
   | l8  | {r1, r2, r3} | {r3, r4}     |
   | l9  | {r3, r4}     | {r5, r4}     |
   | l10 | {r5, r4}     | {}           |
   |-----+--------------+--------------|

** Un premier algorithme (naif) de coloriage de graphe
   let rec colorize : graph -> coloring = fun g ->
     match pick_simplifiable_node g with
     | Some n ->
       let coloring = colorize (g \\ { n }) in
       assign_remaining_color coloring n g
     | None ->
       let coloring = colorize (g \\ { n }) in
       try
        assign_remaining_color coloring n g
       with NoMoreColor -> give_up coloring n
* Cours 16 <2017-03-06>
** Présentation du prochain TD : Hobix vers Fopix, Fopix vers Retrolix
*** Hobix -> Fopix
**** Traduction des fonctions mutuellement récursives
    On suppose pour le moment que les fonctions ne sont pas anonymes,
    cela signifie que l'on transforme les programmes Hobix de la forme:

    fun f1 (x11, ..., x1n) = e1
    and ...
    and fM (xM1, ..., xMK) = eM

    c'est-à-dire des programmes dont les fonctions sont définies à
    "toplevel".

    En Fopix, toutes les fonctions sont mutuellement récursives et
    les identificateurs des fonctions doivent être uniques.

    Comment donc traiter le programme Hobix suivant?

       fun f (x) = x
       and g (x) = f(x)

       val y = f (0)

       fun f (x) = x + 1

       val z = f (0)

     => Il suffit de renommer la seconde occurrence de f en f1 par exemple.

**** Traduction des applications

     Pour le moment, on ne traite que les applications de la forme "f (e1, .., eN)"
     où f est connue et définie à toplevel.

**** Traduction des fonctions anonymes

     Pour le moment, on ne le fait pas!

*** Fopix -> Retrolix
**** Un premier exemple

     Le programme Fopix suivant:

     fun f (x, y) =
       3 * x + 2 * y

     se transforme en Retrolix:

     routine f (x, y):
     locals: u, z, t
       u <- mul 3 x
       z <- mul 2 y
       t <- add z u
       ret t

**** Un second exemple

    fun f (x, y) =
       val x = x + 1;
       val x = y * x;
       x + y

    se compile:

    routine f (x, y) =
       x <- x + 1;
       x <- y * x;
       z <- x + y;
       ret z

    mais par contre:

    fun f (x, y) =
       val y =
         val x = x + 1;
         x;
       x + y

    NE se compile PAS en:

    routine f (x, y) =
      x <- x + 1
      y <- x
      z <- x + y
      ret z

    car f (1, 3) dans hobix vaut : 3 alors dans le code compilé,
    f (1, 3) renvoie 4.

    Pour résoudre ce problème, il suffit de renommer les variables
    dont le nom est déjà utilisé. Dans notre exemple, cela donne:

    fun f (x, y) =
       val y =
         val x1 = x + 1;
         x1;
       x + y

    routine f (x, y) =
      x1 <- x + 1
      y <- x1
      z <- x + y
      ret z

**** Traduction des déclarations de valeurs toplevels de Fopix

     En fopix:

     val x = 3 + 3
     val y = 3 * x

     En retrolix, cela donne:

     val x {
       // Le code qui initialise la variable globale "x"
       locals z
       z <- 3 + 3
       ret z
     }

     val y {
       locals z
       z <- 3 * x
       ret z
     }

**** Traduction des if-then-else

     En fopix:

     fun fact (n) =
       if n == 0 then 1 else n * fact (n - 1)


     En retrolix:

     routine fact (n)
          c <- eq? n 0
          cjmp c == 1, ltrue, lfalse

       ltrue:
          z <- 1
          jmp ljoin

       lfalse:
          k <- n - 1
          y <- fact (k)
	  z <- n * y
	  jmp ljoin

       ljoin:
          ;; join branches
          ret z

** Retour sur les conventions d'appel
*** Introduction du problème

    Le programme Retrolix suivant ne respecte pas les conventions
    d'appels de MIPS.

     routine fact (n)
          c <- eq? n 0
          cjmp c == 1, ltrue, lfalse

       ltrue:
          z <- 1
          jmp ljoin

       lfalse:
          k <- n - 1
          y <- fact (k)
	  z <- n * y
	  jmp ljoin

       ljoin:
          ;; join branches
          ret z

    On pourrait se dire que ce n'est pas un problème car justement
    nous sommes en Retrolix et non en MIPS. Cependant, il est
    nécessaire d'implémenter les conventions d'appel dès Retrolix car
    les conventions d'appel imposent des contraintes sur l'allocation
    de registres. On pourrait se dire de nouveau que l'allocation de
    registres devraient être faite en MIPS et non en
    Retrolix. Cependant, ce serait trop tard car MIPS n'a plus de
    notion de variables mais seulement de mémoire et de registres.

    Pourquoi les conventions d'appel ont une influence sur l'allocation
    de registres? Prenons l'exemple après allocation de registres sans
    implémentation des conventions d'appel, on pourrait obtenir:

     routine fact () // is in $t0
          $a0 <- eq? $t0 0
          cjmp $a0 == 1, ltrue, lfalse

       ltrue:
          $a3 <- 1
          jmp ljoin

       lfalse:
          $t4 <- $t0 - 1
          $a2 <- fact ($t4)
	  $a3 <- $t0 * $a2
	  jmp ljoin

       ljoin:
          ;; join branches
          ret $a3

   On veut plutôt commencer par implémenter les conventions d'appel comme suit:

     routine fact ()
          ymp0 <- $s0
	  ...
          ymp7 <- $s7
	  ymp8 <- $ra
          c <- eq? $a0 0
          cjmp c == 1, ltrue, lfalse

       ltrue:
          z <- 1
          jmp ljoin

       lfalse:
          k <- $a0 - 1
	  x <- $a0
	  $a0 <- k

	  tmp0 <- $t0
	  tmp1 <- $t1
	  tmp2 <- $t2
	  tmp3 <- $t3
	  tmp4 <- $t4
	  tmp5 <- $t5
	  tmp6 <- $t6
	  tmp7 <- $t7
	  tmp8 <- $t8
	  tmp9 <- $t9
          fact ()
	  $t0 <- tmp0
	  $t1 <- tmp1
	  $t2 <- tmp2
	  $t3 <- tmp3
	  $t4 <- tmp4
	  $t5 <- tmp5
	  $t6 <- tmp6
	  $t7 <- tmp7
	  $t8 <- tmp8
	  $t9 <- tmp9
	  y <- $v0
	  z <- x * y
	  jmp ljoin

       ljoin:
          ;; join branches
	  $v0 <- z
	  $ra <- ymp9
	  $s0 <- ymp0
	  ...
	  $s7 <- ymp7


** <2017-03-13>
*** Le module MipsArch
    - Lire MipsArch
*** Modification de la compilation FopixToRetrolix
    - Passage des arguments et du retour.
    - Sauvegarde/Restaurations des registres.
*** Modification de l'analyse de vivacité
    - Les registres définis par les appels de fonctions
*** Modification du coloriage de graphe naïf
    - Utilisation d'un graphe précolorié
** Coloriage d'un graphe avec relation de préférence
*** Fusion de deux nœuds
*** Deux heuristiques
**** Briggs

     - Si en fusionnant a et b dans G, le nombre de noeuds voisins du
       nouveau noeud qui ne sont pas simplifiables est strictement
       inferieur au nombre de couleurs disponibles alors OK.

**** George

     - Si les noeuds non simplifiables et en conflit avec a sont des
       noeuds qui etaient aussi en conflit avec b (ou inversement)
       alors OK.

**** Justifications informelles

     Pourquoi si G était k-coloriable alors après fusion G est encore
     k-coloriable?

***** Briggs

      Après avoir simplifié tous les noeuds adjacents du noeud fusionné,
      il va en rester un nombre strictement inférieur à k donc le noeud
      fusionné sera simplifiable et donc si le graphe sans ce noeud était
      k-coloriable, il sera encore k-coloriable.

***** George

      Soit S l'ensemble des noeuds simplifiables adjacents à "a".

      Si on simplifie S dans G - sans faire la fusion - on obtient
      un graphe G₁.

      Si on simplifie S dans G après fusion, on obtient un graphe
      G₂ qui est un sous-graphe de G₁.

      G₂ est au moins aussi facile à colorier que G₁.

*** Nouvel algorithme
   colorize G colors =
     Pick a node in G which degree < |colors| and with no preference relation.
     There are four cases:
     - G is empty => an empty coloring is fine.
     - there is a node n which degree < |colors|
       let coloring = colorize (G \ { n }) colors in
       let remaining_colors = colors \ colors_of (neighbours(n)) in coloring in
       if remaining_colors = ∅ then
         mark n as spilled
       else
         return (coloring ∪ { n ↦ pick_color in remaining_colors })
     - there are two nodes a and b that love each other.
       if briggs or georges give their blessing then
         colorize (coalesce a b in G) colors
       else
         colorize (remove preference between a b in G) colors
     - otherwise, there is some node n and try optimistic simplification.
*** Design de l'interface du module de Graph

